{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42dd6901",
   "metadata": {},
   "source": [
    "To produce word embeddings using Word2Vec, Gensim is often the library of choice. As a renowned Python library for natural language processing (NLP), Gensim offers comprehensive support for a range of word embedding models, such as Word2Vec, FastText, and Doc2Vec. The following guide provides a detailed walkthrough on leveraging Gensim to create word embeddings with the Word2Vec model, a widely adopted method in the field. To illustrate the algorithm, we present the code below, which is largely adapted from Jake Tae's study on Word2Vec: https://jaketae.github.io/study/word2vec/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b519f",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50fdc659",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Machine learning is the study of computer algorithms that \\\n",
    "improve automatically through experience. It is seen as a \\\n",
    "subset of artificial intelligence. Machine learning algorithms \\\n",
    "build a mathematical model based on sample data, known as \\\n",
    "training data, in order to make predictions or decisions without \\\n",
    "being explicitly programmed to do so. Machine learning algorithms \\\n",
    "are used in a wide variety of applications, such as email filtering \\\n",
    "and computer vision, where it is difficult or infeasible to develop \\\n",
    "conventional algorithms to perform the needed tasks.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6c7df3",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe8c32f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'algorithms',\n",
       " 'that',\n",
       " 'improve',\n",
       " 'automatically',\n",
       " 'through',\n",
       " 'experience',\n",
       " 'it',\n",
       " 'is',\n",
       " 'seen',\n",
       " 'as',\n",
       " 'a',\n",
       " 'subset',\n",
       " 'of',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'build',\n",
       " 'a',\n",
       " 'mathematical',\n",
       " 'model',\n",
       " 'based',\n",
       " 'on',\n",
       " 'sample',\n",
       " 'data',\n",
       " 'known',\n",
       " 'as',\n",
       " 'training',\n",
       " 'data',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'make',\n",
       " 'predictions',\n",
       " 'or',\n",
       " 'decisions',\n",
       " 'without',\n",
       " 'being',\n",
       " 'explicitly',\n",
       " 'programmed',\n",
       " 'to',\n",
       " 'do',\n",
       " 'so',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'are',\n",
       " 'used',\n",
       " 'in',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'applications',\n",
       " 'such',\n",
       " 'as',\n",
       " 'email',\n",
       " 'filtering',\n",
       " 'and',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'where',\n",
       " 'it',\n",
       " 'is',\n",
       " 'difficult',\n",
       " 'or',\n",
       " 'infeasible',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'conventional',\n",
       " 'algorithms',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'the',\n",
       " 'needed',\n",
       " 'tasks']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    pattern = re.compile(r'[A-Za-z]+[\\w^\\']*|[\\w^\\']*[A-Za-z]+[\\w^\\']*')\n",
    "    return pattern.findall(text.lower())\n",
    "\n",
    "tokens = tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa843c61",
   "metadata": {},
   "source": [
    "## Creating look-up table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28be27f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'known': 0,\n",
       " 'through': 1,\n",
       " 'in': 2,\n",
       " 'on': 3,\n",
       " 'are': 4,\n",
       " 'filtering': 5,\n",
       " 'to': 6,\n",
       " 'email': 7,\n",
       " 'decisions': 8,\n",
       " 'used': 9,\n",
       " 'automatically': 10,\n",
       " 'learning': 11,\n",
       " 'experience': 12,\n",
       " 'artificial': 13,\n",
       " 'make': 14,\n",
       " 'predictions': 15,\n",
       " 'improve': 16,\n",
       " 'difficult': 17,\n",
       " 'conventional': 18,\n",
       " 'as': 19,\n",
       " 'study': 20,\n",
       " 'training': 21,\n",
       " 'order': 22,\n",
       " 'develop': 23,\n",
       " 'subset': 24,\n",
       " 'being': 25,\n",
       " 'machine': 26,\n",
       " 'model': 27,\n",
       " 'where': 28,\n",
       " 'it': 29,\n",
       " 'intelligence': 30,\n",
       " 'that': 31,\n",
       " 'of': 32,\n",
       " 'vision': 33,\n",
       " 'sample': 34,\n",
       " 'computer': 35,\n",
       " 'programmed': 36,\n",
       " 'without': 37,\n",
       " 'do': 38,\n",
       " 'variety': 39,\n",
       " 'applications': 40,\n",
       " 'and': 41,\n",
       " 'infeasible': 42,\n",
       " 'based': 43,\n",
       " 'perform': 44,\n",
       " 'the': 45,\n",
       " 'so': 46,\n",
       " 'mathematical': 47,\n",
       " 'build': 48,\n",
       " 'explicitly': 49,\n",
       " 'data': 50,\n",
       " 'a': 51,\n",
       " 'wide': 52,\n",
       " 'tasks': 53,\n",
       " 'algorithms': 54,\n",
       " 'or': 55,\n",
       " 'is': 56,\n",
       " 'such': 57,\n",
       " 'needed': 58,\n",
       " 'seen': 59}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapping(tokens):\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    \n",
    "    for i, token in enumerate(set(tokens)):\n",
    "        word_to_id[token] = i\n",
    "        id_to_word[i] = token\n",
    "    \n",
    "    return word_to_id, id_to_word\n",
    "\n",
    "word_to_id, id_to_word = mapping(tokens)\n",
    "word_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4758cc",
   "metadata": {},
   "source": [
    "## Generating Training Data\n",
    "\n",
    "Now that we have tokenized the text and created lookup tables, we can now proceed to generating the actual training data, which are going to take the form of matrices. Since tokens are still in the form of strings, we need to encode them numerically using one-hot vectorization. We also need to generate a bundle of input and target values, as this is a supervised learning technique.\n",
    "\n",
    "To generate training data, we loop through each word (or token) in the sentence. In each loop, we look at words to the left and right of the input word. For example in sentence 'Machine learning is the study of computer algorithms', the taret word now is 'study'. Then we would generate the following input and prediction pairs part of the training data. \n",
    "\n",
    "['study', 'is']\n",
    "['study', 'the']\n",
    "['study', 'of']\n",
    "['study', 'computer']\n",
    "\n",
    "Note that the window size is two, which is why we look up to two words to the left and right of the input word. So in a way, we can understand this as forcing the model to understand a rough sense of context—the ability to see which words tend to stick together. In our own example, for instance, we would see a lot of [\"machine\", \"learning\"], meaning that the model should be able to capture the close contextual affinity between these two words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c0def",
   "metadata": {},
   "source": [
    "Below is the code that generates training data using the algorithm described above. We basically iterate over the tokenized data and generate pairs. One technicality here is that, for the first and last few tokens, it may not be possible to obtain words to the left or right of that input token. In those cases, we simply don’t consider these word pairs and look at only what is feasible without causing IndexErrors. Also note that we create X and y separately instead of putting them in tuple form as demonstrated above. This is just for convenience with other matrix operations later on in the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "170501c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((330, 60),\n",
       " (330, 60),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 1, 0]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_training_data(tokens, word_to_id, window):\n",
    "    X = []\n",
    "    y = []\n",
    "    n_tokens = len(tokens)\n",
    "    \n",
    "    for i in range(n_tokens):\n",
    "        idx = concat(\n",
    "            range(max(0, i - window), i), \n",
    "            range(i, min(n_tokens, i + window + 1))\n",
    "        )\n",
    "        for j in idx:\n",
    "            if i == j:\n",
    "                continue\n",
    "            X.append(one_hot_encode(word_to_id[tokens[i]], len(word_to_id)))\n",
    "            y.append(one_hot_encode(word_to_id[tokens[j]], len(word_to_id)))\n",
    "    \n",
    "    return np.asarray(X), np.asarray(y)\n",
    "\n",
    "def concat(*iterables):\n",
    "    for iterable in iterables:\n",
    "        yield from iterable\n",
    "        \n",
    "def one_hot_encode(id, vocab_size):\n",
    "    res = [0] * vocab_size\n",
    "    res[id] = 1\n",
    "    return res\n",
    "\n",
    "X, y = generate_training_data(tokens, word_to_id, 2)\n",
    "X.shape,y.shape,X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f623a24",
   "metadata": {},
   "source": [
    "## The Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e6a75de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network(vocab_size, n_embedding):\n",
    "    model = {\n",
    "        \"w1\": np.random.randn(vocab_size, n_embedding),\n",
    "        \"w2\": np.random.randn(n_embedding, vocab_size)\n",
    "    }\n",
    "    return model\n",
    "\n",
    "model = init_network(len(word_to_id), 10)\n",
    "\n",
    "def forward(model, X, return_cache=True):\n",
    "    cache = {}\n",
    "    \n",
    "    cache[\"a1\"] = X @ model[\"w1\"]\n",
    "    cache[\"a2\"] = cache[\"a1\"] @ model[\"w2\"]\n",
    "    cache[\"z\"] = softmax(cache[\"a2\"])\n",
    "    \n",
    "    if not return_cache:\n",
    "        return cache[\"z\"]\n",
    "    return cache\n",
    "\n",
    "def softmax(X):\n",
    "    res = []\n",
    "    for x in X:\n",
    "        exp = np.exp(x)\n",
    "        res.append(exp / exp.sum())\n",
    "    return res\n",
    "\n",
    "def backward(model, X, y, alpha):\n",
    "    cache  = forward(model, X)\n",
    "    da2 = cache[\"z\"] - y\n",
    "    dw2 = cache[\"a1\"].T @ da2\n",
    "    da1 = da2 @ model[\"w2\"].T\n",
    "    dw1 = X.T @ da1\n",
    "    assert(dw2.shape == model[\"w2\"].shape)\n",
    "    assert(dw1.shape == model[\"w1\"].shape)\n",
    "    model[\"w1\"] -= alpha * dw1\n",
    "    model[\"w2\"] -= alpha * dw2\n",
    "    return cross_entropy(cache[\"z\"], y)\n",
    "\n",
    "def cross_entropy(z, y):\n",
    "    return - np.sum(np.log(z) * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be4f6ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"490.04375pt\" height=\"329.525312pt\" viewBox=\"0 0 490.04375 329.525312\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-03-04T10:44:16.696470</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 329.525312 \n",
       "L 490.04375 329.525312 \n",
       "L 490.04375 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 36.44375 306.18 \n",
       "L 482.84375 306.18 \n",
       "L 482.84375 7.2 \n",
       "L 36.44375 7.2 \n",
       "z\n",
       "\" style=\"fill: #eaeaf2\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 56.734659 306.18 \n",
       "L 56.734659 7.2 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\"/>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(53.95419 320.337812)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
       "Q 266 3072 433 3567 \n",
       "Q 600 4063 929 4331 \n",
       "Q 1259 4600 1759 4600 \n",
       "Q 2128 4600 2406 4451 \n",
       "Q 2684 4303 2865 4023 \n",
       "Q 3047 3744 3150 3342 \n",
       "Q 3253 2941 3253 2259 \n",
       "Q 3253 1453 3087 958 \n",
       "Q 2922 463 2592 192 \n",
       "Q 2263 -78 1759 -78 \n",
       "Q 1097 -78 719 397 \n",
       "Q 266 969 266 2259 \n",
       "z\n",
       "M 844 2259 \n",
       "Q 844 1131 1108 757 \n",
       "Q 1372 384 1759 384 \n",
       "Q 2147 384 2411 759 \n",
       "Q 2675 1134 2675 2259 \n",
       "Q 2675 3391 2411 3762 \n",
       "Q 2147 4134 1753 4134 \n",
       "Q 1366 4134 1134 3806 \n",
       "Q 844 3388 844 2259 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 139.554696 306.18 \n",
       "L 139.554696 7.2 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\"/>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 10 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(133.993759 320.337812)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
       "L 1822 0 \n",
       "L 1822 3584 \n",
       "Q 1619 3391 1289 3197 \n",
       "Q 959 3003 697 2906 \n",
       "L 697 3450 \n",
       "Q 1169 3672 1522 3987 \n",
       "Q 1875 4303 2022 4600 \n",
       "L 2384 4600 \n",
       "L 2384 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 222.374733 306.18 \n",
       "L 222.374733 7.2 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\"/>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 20 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(216.813796 320.337812)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
       "L 3222 0 \n",
       "L 194 0 \n",
       "Q 188 203 259 391 \n",
       "Q 375 700 629 1000 \n",
       "Q 884 1300 1366 1694 \n",
       "Q 2113 2306 2375 2664 \n",
       "Q 2638 3022 2638 3341 \n",
       "Q 2638 3675 2398 3904 \n",
       "Q 2159 4134 1775 4134 \n",
       "Q 1369 4134 1125 3890 \n",
       "Q 881 3647 878 3216 \n",
       "L 300 3275 \n",
       "Q 359 3922 746 4261 \n",
       "Q 1134 4600 1788 4600 \n",
       "Q 2447 4600 2831 4234 \n",
       "Q 3216 3869 3216 3328 \n",
       "Q 3216 3053 3103 2787 \n",
       "Q 2991 2522 2730 2228 \n",
       "Q 2469 1934 1863 1422 \n",
       "Q 1356 997 1212 845 \n",
       "Q 1069 694 975 541 \n",
       "L 3222 541 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 305.19477 306.18 \n",
       "L 305.19477 7.2 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\"/>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 30 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(299.633833 320.337812)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-33\" d=\"M 269 1209 \n",
       "L 831 1284 \n",
       "Q 928 806 1161 595 \n",
       "Q 1394 384 1728 384 \n",
       "Q 2125 384 2398 659 \n",
       "Q 2672 934 2672 1341 \n",
       "Q 2672 1728 2419 1979 \n",
       "Q 2166 2231 1775 2231 \n",
       "Q 1616 2231 1378 2169 \n",
       "L 1441 2663 \n",
       "Q 1497 2656 1531 2656 \n",
       "Q 1891 2656 2178 2843 \n",
       "Q 2466 3031 2466 3422 \n",
       "Q 2466 3731 2256 3934 \n",
       "Q 2047 4138 1716 4138 \n",
       "Q 1388 4138 1169 3931 \n",
       "Q 950 3725 888 3313 \n",
       "L 325 3413 \n",
       "Q 428 3978 793 4289 \n",
       "Q 1159 4600 1703 4600 \n",
       "Q 2078 4600 2393 4439 \n",
       "Q 2709 4278 2876 4000 \n",
       "Q 3044 3722 3044 3409 \n",
       "Q 3044 3113 2884 2869 \n",
       "Q 2725 2625 2413 2481 \n",
       "Q 2819 2388 3044 2092 \n",
       "Q 3269 1797 3269 1353 \n",
       "Q 3269 753 2831 336 \n",
       "Q 2394 -81 1725 -81 \n",
       "Q 1122 -81 723 278 \n",
       "Q 325 638 269 1209 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 388.014808 306.18 \n",
       "L 388.014808 7.2 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\"/>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 40 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(382.45387 320.337812)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-34\" d=\"M 2069 0 \n",
       "L 2069 1097 \n",
       "L 81 1097 \n",
       "L 81 1613 \n",
       "L 2172 4581 \n",
       "L 2631 4581 \n",
       "L 2631 1613 \n",
       "L 3250 1613 \n",
       "L 3250 1097 \n",
       "L 2631 1097 \n",
       "L 2631 0 \n",
       "L 2069 0 \n",
       "z\n",
       "M 2069 1613 \n",
       "L 2069 3678 \n",
       "L 634 1613 \n",
       "L 2069 1613 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 470.834845 306.18 \n",
       "L 470.834845 7.2 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\"/>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 50 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(465.273907 320.337812)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-35\" d=\"M 266 1200 \n",
       "L 856 1250 \n",
       "Q 922 819 1161 601 \n",
       "Q 1400 384 1738 384 \n",
       "Q 2144 384 2425 690 \n",
       "Q 2706 997 2706 1503 \n",
       "Q 2706 1984 2436 2262 \n",
       "Q 2166 2541 1728 2541 \n",
       "Q 1456 2541 1237 2417 \n",
       "Q 1019 2294 894 2097 \n",
       "L 366 2166 \n",
       "L 809 4519 \n",
       "L 3088 4519 \n",
       "L 3088 3981 \n",
       "L 1259 3981 \n",
       "L 1013 2750 \n",
       "Q 1425 3038 1878 3038 \n",
       "Q 2478 3038 2890 2622 \n",
       "Q 3303 2206 3303 1553 \n",
       "Q 3303 931 2941 478 \n",
       "Q 2500 -78 1738 -78 \n",
       "Q 1113 -78 717 272 \n",
       "Q 322 622 266 1200 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-35\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 36.44375 278.057189 \n",
       "L 482.84375 278.057189 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\"/>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 750 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(12.760938 281.636095)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-37\" d=\"M 303 3981 \n",
       "L 303 4522 \n",
       "L 3269 4522 \n",
       "L 3269 4084 \n",
       "Q 2831 3619 2401 2847 \n",
       "Q 1972 2075 1738 1259 \n",
       "Q 1569 684 1522 0 \n",
       "L 944 0 \n",
       "Q 953 541 1156 1306 \n",
       "Q 1359 2072 1739 2783 \n",
       "Q 2119 3494 2547 3981 \n",
       "L 303 3981 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-37\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 36.44375 243.39115 \n",
       "L 482.84375 243.39115 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\"/>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 1000 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 246.970056)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 36.44375 208.725111 \n",
       "L 482.84375 208.725111 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\"/>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 1250 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 212.304017)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 36.44375 174.059071 \n",
       "L 482.84375 174.059071 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\"/>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 1500 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 177.637978)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path d=\"M 36.44375 139.393032 \n",
       "L 482.84375 139.393032 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\"/>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 1750 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 142.971938)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-37\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path d=\"M 36.44375 104.726993 \n",
       "L 482.84375 104.726993 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\"/>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 2000 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 108.305899)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <path d=\"M 36.44375 70.060954 \n",
       "L 482.84375 70.060954 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_26\"/>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 2250 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 73.63986)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <path d=\"M 36.44375 35.394914 \n",
       "L 482.84375 35.394914 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_28\"/>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 2500 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 38.973821)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_29\">\n",
       "    <path d=\"M 56.734659 20.79 \n",
       "L 65.016663 148.720972 \n",
       "L 73.298667 189.887701 \n",
       "L 81.58067 209.473337 \n",
       "L 89.862674 222.103932 \n",
       "L 98.144678 231.522797 \n",
       "L 106.426681 239.058342 \n",
       "L 114.708685 245.366336 \n",
       "L 122.990689 250.790991 \n",
       "L 131.272692 255.524258 \n",
       "L 139.554696 259.699421 \n",
       "L 147.8367 263.423647 \n",
       "L 156.118704 266.771382 \n",
       "L 164.400707 269.785528 \n",
       "L 172.682711 272.494712 \n",
       "L 180.964715 274.927941 \n",
       "L 189.246718 277.11618 \n",
       "L 197.528722 279.086843 \n",
       "L 205.810726 280.862372 \n",
       "L 214.09273 282.462213 \n",
       "L 222.374733 283.904463 \n",
       "L 230.656737 285.206552 \n",
       "L 238.938741 286.385077 \n",
       "L 247.220744 287.455048 \n",
       "L 255.502748 288.429232 \n",
       "L 263.784752 289.318011 \n",
       "L 272.066756 290.129641 \n",
       "L 280.348759 290.870268 \n",
       "L 288.630763 291.542495 \n",
       "L 296.912767 292.134804 \n",
       "L 305.19477 292.59 \n",
       "L 313.476774 292.564939 \n",
       "L 321.758778 292.265818 \n",
       "L 330.040782 289.277797 \n",
       "L 338.322785 290.906632 \n",
       "L 346.604789 291.479467 \n",
       "L 354.886793 290.758769 \n",
       "L 363.168796 286.245236 \n",
       "L 371.4508 285.986493 \n",
       "L 379.732804 289.756724 \n",
       "L 388.014808 288.057382 \n",
       "L 396.296811 288.820197 \n",
       "L 404.578815 290.123856 \n",
       "L 412.860819 287.804882 \n",
       "L 421.142822 287.853542 \n",
       "L 429.424826 288.278821 \n",
       "L 437.70683 286.902994 \n",
       "L 445.988833 287.257128 \n",
       "L 454.270837 289.408772 \n",
       "L 462.552841 291.267056 \n",
       "\" clip-path=\"url(#pb1e6c310db)\" style=\"fill: none; stroke: #87ceeb; stroke-width: 1.75; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 36.44375 306.18 \n",
       "L 36.44375 7.2 \n",
       "\" style=\"fill: none\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 482.84375 306.18 \n",
       "L 482.84375 7.2 \n",
       "\" style=\"fill: none\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 36.44375 306.18 \n",
       "L 482.84375 306.18 \n",
       "\" style=\"fill: none\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 36.44375 7.2 \n",
       "L 482.84375 7.2 \n",
       "\" style=\"fill: none\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pb1e6c310db\">\n",
       "   <rect x=\"36.44375\" y=\"7.2\" width=\"446.4\" height=\"298.98\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "n_iter = 50\n",
    "learning_rate = 0.05\n",
    "\n",
    "history = [backward(model, X, y, learning_rate) for _ in range(n_iter)]\n",
    "\n",
    "plt.plot(range(len(history)), history, color=\"skyblue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96a972",
   "metadata": {},
   "source": [
    "An obvious sanity check we can perform is to see which token our model predicts given the word “learning.” If the model was trained properly, the most likely word should understandably be “machine.” And indeed, when that is the result we get: notice that “machine” is at the top of the list of tokens, sorted by degree of affinity with “learning.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a10e2920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine\n",
      "algorithms\n",
      "so\n",
      "intelligence\n",
      "build\n",
      "the\n",
      "is\n",
      "are\n",
      "learning\n",
      "subset\n",
      "artificial\n",
      "or\n",
      "conventional\n",
      "without\n",
      "do\n",
      "explicitly\n",
      "seen\n",
      "a\n",
      "that\n",
      "used\n",
      "develop\n",
      "being\n",
      "through\n",
      "perform\n",
      "where\n",
      "decisions\n",
      "data\n",
      "study\n",
      "applications\n",
      "make\n",
      "it\n",
      "model\n",
      "known\n",
      "infeasible\n",
      "wide\n",
      "in\n",
      "needed\n",
      "mathematical\n",
      "difficult\n",
      "programmed\n",
      "experience\n",
      "tasks\n",
      "based\n",
      "automatically\n",
      "predictions\n",
      "variety\n",
      "computer\n",
      "to\n",
      "such\n",
      "vision\n",
      "of\n",
      "order\n",
      "sample\n",
      "as\n",
      "on\n",
      "training\n",
      "email\n",
      "improve\n",
      "and\n",
      "filtering\n"
     ]
    }
   ],
   "source": [
    "learning = one_hot_encode(word_to_id[\"learning\"], len(word_to_id))\n",
    "result = forward(model, [learning], return_cache=False)[0]\n",
    "\n",
    "for word in (id_to_word[id] for id in np.argsort(result)[::-1]):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0719836",
   "metadata": {},
   "source": [
    "## Using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f06e61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Applications/anaconda3/lib/python3.8/site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Applications/anaconda3/lib/python3.8/site-packages (from gensim) (1.21.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Applications/anaconda3/lib/python3.8/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Applications/anaconda3/lib/python3.8/site-packages (from gensim) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e804804",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    ['this', 'is', 'the', 'first', 'sentence'],\n",
    "    ['this', 'is', 'the', 'second', 'sentence'],\n",
    "    ['this', 'is', 'the', 'third', 'sentence']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a29f8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.1322715e-03 -4.4573355e-03 -1.0683584e-03  1.0063648e-03\n",
      " -1.9111396e-04  1.1481761e-03  6.1138608e-03 -2.0272731e-05\n",
      " -3.2459665e-03 -1.5107298e-03  5.8972980e-03  1.5141011e-03\n",
      " -7.2426320e-04  9.3332455e-03 -4.9212836e-03 -8.3841087e-04\n",
      "  9.1754105e-03  6.7494274e-03  1.5028549e-03 -8.8825608e-03\n",
      "  1.1487460e-03 -2.2882556e-03  9.3682362e-03  1.2099266e-03\n",
      "  1.4900636e-03  2.4064088e-03 -1.8360066e-03 -4.9996353e-03\n",
      "  2.3242951e-04 -2.0141816e-03  6.6009331e-03  8.9401221e-03\n",
      " -6.7475555e-04  2.9770136e-03 -6.1076544e-03  1.6993236e-03\n",
      " -6.9262339e-03 -8.6940266e-03 -5.9002042e-03 -8.9564752e-03\n",
      "  7.2775935e-03 -5.7720328e-03  8.2763508e-03 -7.2435453e-03\n",
      "  3.4216738e-03  9.6749971e-03 -7.7854488e-03 -9.9450592e-03\n",
      " -4.3291473e-03 -2.6831317e-03 -2.7128935e-04 -8.8315513e-03\n",
      " -8.6175585e-03  2.8002094e-03 -8.2064085e-03 -9.0693375e-03\n",
      " -2.3404669e-03 -8.6318087e-03 -7.0566512e-03 -8.4011508e-03\n",
      " -3.0133009e-04 -4.5642997e-03  6.6271736e-03  1.5271592e-03\n",
      " -3.3414769e-03  6.1089708e-03 -6.0132863e-03 -4.6561696e-03\n",
      " -7.2075105e-03 -4.3365811e-03 -1.8093300e-03  6.4896415e-03\n",
      " -2.7703929e-03  4.9189664e-03  6.9044423e-03 -7.4637057e-03\n",
      "  4.5648501e-03  6.1269784e-03 -2.9544758e-03  6.6250204e-03\n",
      "  6.1258795e-03 -6.4434861e-03 -6.7645526e-03  2.5389576e-03\n",
      " -1.6238189e-03 -6.0651279e-03  9.4992090e-03 -5.1301480e-03\n",
      " -6.5540983e-03 -1.1988640e-04 -2.7014280e-03  4.4440030e-04\n",
      " -3.5374593e-03 -4.1933061e-04 -7.0861576e-04  8.2282064e-04\n",
      "  8.1948163e-03 -5.7367086e-03 -1.6595292e-03  5.5716061e-03]\n",
      "[('is', 0.14595064520835876), ('this', 0.041577357798814774), ('third', 0.03476494550704956), ('second', 0.019152294844388962), ('sentence', 0.01613471284508705), ('the', -0.11410725116729736)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Assuming 'sentences' is your list of tokenized sentences\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "vector = model.wv['first']\n",
    "print(vector)\n",
    "similar_words = model.wv.most_similar('first')\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc115fd",
   "metadata": {},
   "source": [
    "## using existing trained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# If your model is Word2Vec\n",
    "model = Word2Vec.load(\"path_to_your_model/word2vec.model\")\n",
    "\n",
    "#For models saved as KeyedVectors:\n",
    "#model = KeyedVectors.load(\"path_to_your_model/wordvectors.kv\")\n",
    "\n",
    "# Get the vector for a word\n",
    "word_vector = model.wv['example']  # Replace 'example' with your word\n",
    "\n",
    "print(word_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
